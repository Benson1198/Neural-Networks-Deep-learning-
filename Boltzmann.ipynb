{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Boltzmann Machines Tutorials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-4JnSQ-DE3o76FmvpRR0iQ9vGSTVhwPI",
      "authorship_tag": "ABX9TyMQzLPd4AoHL3yHw/7N4SW4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benson1198/Neural-Networks-Deep-learning-/blob/master/Boltzmann.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O_C8SKspsFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2611e5a-41db-45cf-c27f-8e2e4efb92c7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tTZuTkZs8ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JPChuBPnMVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = pd.read_csv('/content/drive/My Drive/ml-1m/movies.dat', sep = '::', header = None,engine = 'python' ,encoding='latin-1')\n",
        "users = pd.read_csv('/content/drive/My Drive/ml-1m/users.dat', sep = '::', header = None,engine = 'python' ,encoding='latin-1')\n",
        "ratings = pd.read_csv('/content/drive/My Drive/ml-1m/ratings.dat', sep = '::', header = None,engine = 'python' ,encoding='latin-1')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwun0ILhnNHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = pd.read_csv('/content/drive/My Drive/ml-100k/u1.base', delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBd9C7a7IgeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = pd.read_csv('/content/drive/My Drive/ml-100k/u1.test', delimiter = '\\t')\n",
        "test_set = np.array(training_set, dtype = 'int')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpwDCAHInNWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b42d84d-53f1-4c18-b6b1-802cede9a92c"
      },
      "source": [
        "print((type(training_set)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttH1hxWenNfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the Maximum no. of Users and Movies from both Training and Test Set\n",
        "\n",
        "nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]),max(test_set[:,1])))\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2izNBbo6nNqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "708dc545-03a5-4908-8cc6-98cab9bbfc71"
      },
      "source": [
        "print(nb_users)\n",
        "print(nb_movies)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "943\n",
            "1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wJgg19c18Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the data into arrays with Users in Rows and Movies in Columns\n",
        "\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1,nb_users + 1):\n",
        "    id_movies = data[:,1][data[:,0] == id_users]\n",
        "    id_ratings = data[:,2][data[:,0] == id_users]\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies-1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data\n",
        "\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AjY-iNl18Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting data into Torch Tensors\n",
        "\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4msC3xkw18kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the ratings in binary form (Liked = 1, Unliked = 0 & Not Rated = -1)\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1\n",
        " "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Hu4p3R18vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the architecture of Neural Network\n",
        "class RBM():\n",
        "  def __init__(self,nv,nh):\n",
        "    self.W = torch.randn(nh,nv)\n",
        "    self.a = torch.randn(1,nh)\n",
        "    self.b = torch.randn(1,nv)\n",
        "\n",
        "  def sample_h(self,x):\n",
        "    wx = torch.mm(x,self.W.t())\n",
        "    activation = wx + self.a.expand_as(wx)\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "\n",
        "  def sample_v(self,y):\n",
        "    wy = torch.mm(y,self.W)\n",
        "    activation = wy + self.b.expand_as(wy)\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "\n",
        "  def train(self,v0,vk,ph0,phk):\n",
        "    self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "    self.b += torch.sum((v0-vk),0)\n",
        "    self.a += torch.sum((ph0-phk),0)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gahj2FQ185U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiating an RBM object\n",
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "\n",
        "rbm = RBM(nv,nh)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sikxu4Z719CM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "41cb5e6f-520d-442d-eecd-e1f4c0ba509e"
      },
      "source": [
        "# Training the RBM\n",
        "nb_epoch = 10\n",
        "for epoch in range(0,nb_epoch+1):\n",
        "  train_loss  = 0\n",
        "  s = 0.\n",
        "  for id_user in range(0,nb_users-batch_size,batch_size):\n",
        "    vk = training_set[id_user:id_user+batch_size]\n",
        "    v0 = training_set[id_user:id_user+batch_size]\n",
        "    ph0,_ = rbm.sample_h(v0)\n",
        "    for k in range(10):\n",
        "      _,hk = rbm.sample_h(vk)\n",
        "      _,vk = rbm.sample_v(hk)\n",
        "      vk[v0<0] = v0[v0<0]\n",
        "    phk,_ = rbm.sample_h(vk)\n",
        "\n",
        "    rbm.train(v0,vk,ph0,phk)\n",
        "    train_loss += torch.mean(torch.abs(v0[v0>=0]-vk[v0>=0]))\n",
        "    s += 1.\n",
        "  print('epoch:'+str(epoch)+ ' loss: ' + str(train_loss/s))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 loss: tensor(0.3363)\n",
            "epoch:1 loss: tensor(0.2496)\n",
            "epoch:2 loss: tensor(0.2457)\n",
            "epoch:3 loss: tensor(0.2487)\n",
            "epoch:4 loss: tensor(0.2479)\n",
            "epoch:5 loss: tensor(0.2485)\n",
            "epoch:6 loss: tensor(0.2470)\n",
            "epoch:7 loss: tensor(0.2502)\n",
            "epoch:8 loss: tensor(0.2486)\n",
            "epoch:9 loss: tensor(0.2456)\n",
            "epoch:10 loss: tensor(0.2476)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oDD4Wm7clwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f2d41bd-0abd-4876-db15-a030b9d99848"
      },
      "source": [
        "# Testing the RBM\n",
        "test_loss  = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "  v = training_set[id_user:id_user+ 1]\n",
        "  vt = test_set[id_user:id_user+ 1]\n",
        "  if len(vt[vt>=0]) >0:\n",
        "    _,h = rbm.sample_h(v)\n",
        "    _,v = rbm.sample_v(h)\n",
        "\n",
        "  test_loss += torch.mean(torch.abs(vt[vt>=0]-v[vt>=0]))\n",
        "  s += 1.\n",
        "print('Test loss: ' + str(test_loss/s))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: tensor(0.2495)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndGeS-ZO19LE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB7qpfb519UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ_hwpZb19c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}